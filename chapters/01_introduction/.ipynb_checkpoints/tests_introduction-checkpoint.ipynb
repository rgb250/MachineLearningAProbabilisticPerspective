{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b23834-ce14-4aa1-a7bf-b2c1142f5d14",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e957a8-6ce3-4dac-87f1-806a6cd4c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests    # send HTTP requests\n",
    "import os          # interact with the operating system \n",
    "\n",
    "import gzip        # compress (or decompress) like the GNU program gzip (or gunzip)\n",
    "import shutil      # perform high-level operations on files and collection of files\n",
    "\n",
    "import numpy as np # numerical computation\n",
    "\n",
    "import pickle      # save data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f19a98-ef87-43d4-8889-0cbdd92b2ac0",
   "metadata": {},
   "source": [
    "### Download necessary materials from Mixed National Institute of Standards and Technology ([MNIST](http://yann.lecun.com/exdb/mnist/))\n",
    "\n",
    "Hypertext Transfer Protocol (HTTP) is designed to enable communication between clients and servers.  \n",
    "**GET**  is used to *request* data from a specified ressource.  \n",
    "**POST** is used to *send* data to a server to create/update a ressource.\n",
    "[Ref.](https://www.w3schools.com/tags/ref_httpmethods.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec12ec34-d469-45ca-b199-9428d5621886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz  has been downloaded  with a size of  9912422  bytes\n",
      "train-labels-idx1-ubyte.gz  has been downloaded  with a size of  28881  bytes\n",
      "t10k-images-idx3-ubyte.gz  has been downloaded  with a size of  1648877  bytes\n",
      "t10k-labels-idx1-ubyte.gz  has been downloaded  with a size of  4542  bytes\n"
     ]
    }
   ],
   "source": [
    "list_file = ['train-images-idx3-ubyte.gz', \n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "folder = './data'\n",
    "if not os.path.exists(folder):                                     # create folder data if it does not exist\n",
    "    os.makedirs(folder)\n",
    "\n",
    "url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "bool_ind = 0\n",
    "for file in list_file:\n",
    "    cond = (os.path.isfile(os.path.join(folder, file)) or \\\n",
    "            os.path.isfile(os.path.join(folder, file.split('.')[0])))\n",
    "    new_file = os.path.join(folder, file)\n",
    "    if not cond:                                                    # check if the given file is present (with or without its extension)\n",
    "        with open(new_file, 'wb') as f:                             # if does not create a file with filename without extentsion\n",
    "            r = requests.get(url+file)                              # download it \n",
    "            f.write(r.content)                                      # copy the content in the created file\n",
    "    \n",
    "    print(file,\n",
    "          ' is already there' if cond else ' has been downloaded',  # In order to check if the sizes are the same as the ones indicated on the MNIST site.\n",
    "          ' with a size of ', os.path.getsize(new_file), ' bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89b637-ac22-491e-90c6-135228376865",
   "metadata": {},
   "source": [
    "### Decompress the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d4aab70-c2c9-4529-8d07-eb19576531e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzip  train-images-idx3-ubyte.gz  as  train-images-idx3-ubyte\n",
      "Unzip  train-labels-idx1-ubyte.gz  as  train-labels-idx1-ubyte\n",
      "Unzip  t10k-images-idx3-ubyte.gz  as  t10k-images-idx3-ubyte\n",
      "Unzip  t10k-labels-idx1-ubyte.gz  as  t10k-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "for file in list_file:\n",
    "    cond = os.path.isfile(os.path.join(folder, file.split('.gz')[0]))\n",
    "    if not cond:\n",
    "        zip_file = os.path.join(folder, file)\n",
    "        unzip_file = os.path.join(folder, file.split('.gz')[0])\n",
    "        with gzip.open(zip_file, 'rb') as zip_f: # automatically compress or decompress the data so that it looks like an ordinary \"file object\"\n",
    "            with open(unzip_file, 'wb') as unzip_f:\n",
    "                shutil.copyfileobj(zip_f, unzip_f) # copy the content of a file object to another one           \n",
    "    print('Already unzip ' if cond else 'Unzip ' , file, ' as ', file.split('.gz')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b001cff-6bc3-4a1b-bfbe-58a04441c1d2",
   "metadata": {},
   "source": [
    "### Adapting the data in order to operate on it\n",
    "\n",
    "I have been inspired by the work of **Ghosh 4 AI** with his [video](https://www.youtube.com/watch?v=6xar6bxD80g) and his [github repository](https://github.com/Ghosh4AI/Data-Processors), thanks to him! \n",
    "\n",
    "Organization of the binary files  \n",
    "The training files for labels and images are below, for the test files just the number of labels/images change.\n",
    "![training](./images/image_training.png)  \n",
    "\n",
    "![training](./images/label_training.png)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2334eb-fbb6-4ca1-98d1-d9a1bac2a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_type = {'images': {'train': 0, 'test': 0, 'row_nb': 0, 'col_nb': 0},              # to retrieve the header information of the binary files\n",
    "            'labels': {'train': 0, 'test': 0}} \n",
    "\n",
    "dct_data = {'images': {'train': None, 'test': None},                                  # to create the data structure\n",
    "            'labels': {'train': None, 'test': None}}\n",
    "\n",
    "           \n",
    "\n",
    "list_file = [f for f in os.listdir(folder) if not f.endswith('.gz')]                  # consider only decompressed files\n",
    "for file in list_file:\n",
    "    nature = 'images' if 'images' in file else 'labels'\n",
    "    category = 'train' if 'train' in file else 'test'\n",
    "    offset = 16 if 'images' in file else 8                                            # index from which the header information stops and the data appears in the binary files\n",
    "    with open(os.path.join(folder, file), 'rb') as f:\n",
    "        content = f.read()\n",
    "    dct_type[nature][category] = int.from_bytes(content[4: 8], byteorder='big')       # fill out the 'train' and 'test' size information from the header\n",
    "    data = np.frombuffer(content, dtype=np.dtype('u1'), offset=offset)                # translate the binary data in interger (np.dtype('u1'): unsigned byte)\n",
    "    tpl = (dct_type[nature][category], )                                              # tuple containing the number of images ( or labels)\n",
    "    if nature=='images':\n",
    "        dct_type[nature]['row_nb'] = int.from_bytes(content[8: 12], byteorder='big')  # for images the number of pixels by row\n",
    "        dct_type[nature]['col_nb'] = int.from_bytes(content[12: 16], byteorder='big') # by column\n",
    "        tpl += (dct_type[nature]['row_nb'], dct_type[nature]['col_nb'], )             # add the 2 last information to the tuple \n",
    "    dct_data[nature][category] = data.reshape(tpl)                                    # reshape the data as a vector (for labels) or matrix (for images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86eec47-76fd-4f7c-afb7-86c033eb70ff",
   "metadata": {},
   "source": [
    "#### Save data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fdec825-e32b-46a3-8325-a15d38568754",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(folder, 'mnist_data.pkl'), 'wb') as pickle_data:\n",
    "    pickle.dump(dct_data, pickle_data)                                  # keep the data structure, in order to reuse it directly "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
